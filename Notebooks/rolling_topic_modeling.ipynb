{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tfidf and normalizer for bag of words and pre-processing\n",
    "# Import LDA, K-means clustering, NMF, and LSA \n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Import general use tools\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import dill\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import random\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stop_words and create list to hold additions\n",
    "my_additional_stop_words=['15','2628','446','2607','419''____','petition','supreme','rehearing','sugg','plaintiff',\n",
    "                          'error','employés', '000','ch','said','company','united', 'federal', 'district', 'right',\n",
    "                          'id', 'opinion','law', 'case', 'state', 'court','sentence','petitioner','pub','280','ch',\n",
    "                          'statute','case','ct', 'mr', 'ถถ', 'งง', 'zzz','supra','infra','appellant','appellee', 'id',\n",
    "                          '413', '93', '37','1973','act', 'make', 'ante', 'cite', 'claim', 'respondent','rule','shall',\n",
    "                          'judgment','say', 'ed', '2d', 'ct','rev','sup','rep','new york','york']\n",
    "\n",
    "# Update the in-built stopwords list\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Corpora/14th_cleaned_corpora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"year\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one missing year\n",
    "df.at[1807, 'year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.courtlistener.com:80/api/rest/v3/clusters/99548/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resource_uri.iloc[977]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Bag of Words with TF-IDF\n",
    "\n",
    "Get columns required for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id_x', 'year', 'case_name', 'corpora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = df[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>year</th>\n",
       "      <th>case_name</th>\n",
       "      <th>corpora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>88200</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>Worthy v. Commissioners</td>\n",
       "      <td>wall worthyvthe commissionerssupreme court uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>88503</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>Osborn v. Nicholson</td>\n",
       "      <td>wall osbornvnicholson et alsupreme court unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>88662</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>Bradwell v. State</td>\n",
       "      <td>wall bradwellvthe statesupreme court united st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>88661</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>Slaughter-House Cases</td>\n",
       "      <td>wall slaughter-house casesthe butcher benevole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>88800</td>\n",
       "      <td>1874.0</td>\n",
       "      <td>Bartemeyer v. Iowa</td>\n",
       "      <td>wall bartemeyerviowasupreme court united state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>88998</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>Minor v. Happersett</td>\n",
       "      <td>wall minorvhappersettsupreme court united stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>89115</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>Scholey v. Rew</td>\n",
       "      <td>wall scholeyvrewsupreme court united state mr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>89233</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>Raymond v. Thomas</td>\n",
       "      <td>raymondvthomassupreme court united statesmr p ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>89245</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>Walker v. Sauvinet</td>\n",
       "      <td>walkervsauvinetsupreme court united state mr c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>89266</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>United States v. REESE</td>\n",
       "      <td>united statesvreese et alsupreme court united ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>89309</td>\n",
       "      <td>1876.0</td>\n",
       "      <td>United States v. Cruikshank</td>\n",
       "      <td>united statesvcruikshank et alsupreme court un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>89559</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>McMillen v. Anderson</td>\n",
       "      <td>mcmillenvandersonsupreme court united state mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>89446</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>Munn v. Illinois</td>\n",
       "      <td>munnvillinoissupreme court united state mr wc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>89817</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Keith v. Clark</td>\n",
       "      <td>keithvclarksupreme court united statesmr phili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>89656</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Pennoyer v. Neff</td>\n",
       "      <td>pennoyervneffsupreme court united state mr wf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>89834</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Robertson v. Cease</td>\n",
       "      <td>robertsonvceasesupreme court united state mr h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>89675</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Davidson v. New Orleans</td>\n",
       "      <td>davidsonvnew orleanssupreme court united state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>89626</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Hall v. DeCuir</td>\n",
       "      <td>hallvdecuirsupreme court united state mr rh ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>90039</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Strauder v. West Virginia</td>\n",
       "      <td>straudervwest virginiasupreme court united sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>93895</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>In Re City Nat. Bank of Ft. Worth</td>\n",
       "      <td>ct l ed city nat bank ft worth april applicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>90087</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Missouri v. Lewis</td>\n",
       "      <td>missourivlewissupreme court united state mr je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>90041</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Ex Parte Virginia</td>\n",
       "      <td>ex parte virginiasupreme court united state mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>90040</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>Virginia v. Rives</td>\n",
       "      <td>virginiavrivessupreme court united state mr ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>90336</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>Neal v. Delaware</td>\n",
       "      <td>nealvdelawaresupreme court united state mr cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>90879</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Gross v. United States Mortgage Co.</td>\n",
       "      <td>grossvunited state mortgage companysupreme cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>90939</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Louisiana Ex Rel. Folsom v. Mayor and Administ...</td>\n",
       "      <td>state louisiana ex rel folsomvmayor administra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>90898</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>United States v. Gale</td>\n",
       "      <td>united statesvgale anothersupreme court united...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>90728</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>United States v. Harris</td>\n",
       "      <td>united statesvharrissupreme court united state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3343</th>\n",
       "      <td>90717</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Pace v. State of Alabama</td>\n",
       "      <td>ct l ed pacevstate alabamajanuary section code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>90749</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>Bush v. Kentucky</td>\n",
       "      <td>bushvkentuckysupreme court united statesmr lle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>4174308</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Town of Chester v. Laroe Estates, Inc.</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>4154239</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Manuel v. Joliet</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4151827</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Bethune-Hill v. Virginia State Bd. of Elections</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>4181062</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Bristol-Myers Squibb Co. v. Superior Court of ...</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4281072</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Masterpiece Cakeshop, Ltd. v. Colorado Civil R...</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4285135</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Masterpiece Cakeshop, Ltd. v. Colorado Civil R...</td>\n",
       "      <td>summary difference exist document new document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4246856</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Class v. United States</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>4287784</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Abbott v. Perez</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>4264598</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Sessions v. Dimaya</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>4287283</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Currier v. Virginia</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>4285391</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Gill v. Whitford</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>4288403</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>National Institute of Family and Life Advocate...</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>4281071</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Masterpiece Cakeshop, Ltd. v. Colorado Civil R...</td>\n",
       "      <td>summary pm difference exist document new docum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>4246354</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Silvester v. Becerra</td>\n",
       "      <td>cite u thomas j dissentingsupreme court united...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>4280797</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Masterpiece Cakeshop, Ltd. v. Colorado Civil R...</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4405</th>\n",
       "      <td>4278950</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Collins v. Virginia</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>4251727</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>U. S. Bank N. A. v. Village at Lakeridge, LLC</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>4288893</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Janus v. State, County, and Municipal Employees</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>4407339</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Virginia House of Delegates v. Bethune-Hill</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>4407340</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Manhattan Community Access Corp. v. Halleck</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>4410205</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Tennessee Wine and Spirits Retailers Assn. v. ...</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>4407520</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Gamble v. United States</td>\n",
       "      <td>pm compare result old file new file - pdf - ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>4369169</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Timbs v. Indiana</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>4407341</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Gamble v. United States</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>4373152</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Morris County Bd. of Chosen Freeholders v. Fre...</td>\n",
       "      <td>cite u kavanaugh statement k j dissent avanaug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>4410722</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Rucho v. Common Cause</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>4371672</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Garza v. Idaho</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>4407521</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Gamble v. United States</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>4400867</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Nieves v. Bartlett</td>\n",
       "      <td>slip opinion october term syllabus note feasib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>4368899</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cite u thomas j concurringsupreme court united...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_x    year                                          case_name  \\\n",
       "1523    88200  1870.0                            Worthy v. Commissioners   \n",
       "1789    88503  1872.0                                Osborn v. Nicholson   \n",
       "3851    88662  1873.0                                  Bradwell v. State   \n",
       "725     88661  1873.0                              Slaughter-House Cases   \n",
       "250     88800  1874.0                                 Bartemeyer v. Iowa   \n",
       "2508    88998  1875.0                                Minor v. Happersett   \n",
       "1045    89115  1875.0                                     Scholey v. Rew   \n",
       "3904    89233  1876.0                                  Raymond v. Thomas   \n",
       "4491    89245  1876.0                                 Walker v. Sauvinet   \n",
       "422     89266  1876.0                             United States v. REESE   \n",
       "1364    89309  1876.0                        United States v. Cruikshank   \n",
       "2254    89559  1877.0                               McMillen v. Anderson   \n",
       "1485    89446  1877.0                                   Munn v. Illinois   \n",
       "92      89817  1878.0                                     Keith v. Clark   \n",
       "900     89656  1878.0                                   Pennoyer v. Neff   \n",
       "4161    89834  1878.0                                 Robertson v. Cease   \n",
       "3938    89675  1878.0                            Davidson v. New Orleans   \n",
       "1181    89626  1878.0                                     Hall v. DeCuir   \n",
       "3333    90039  1880.0                          Strauder v. West Virginia   \n",
       "1422    93895  1880.0                  In Re City Nat. Bank of Ft. Worth   \n",
       "4219    90087  1880.0                                  Missouri v. Lewis   \n",
       "1288    90041  1880.0                                  Ex Parte Virginia   \n",
       "2161    90040  1880.0                                  Virginia v. Rives   \n",
       "4397    90336  1881.0                                   Neal v. Delaware   \n",
       "4177    90879  1883.0                Gross v. United States Mortgage Co.   \n",
       "1317    90939  1883.0  Louisiana Ex Rel. Folsom v. Mayor and Administ...   \n",
       "1000    90898  1883.0                              United States v. Gale   \n",
       "274     90728  1883.0                            United States v. Harris   \n",
       "3343    90717  1883.0                           Pace v. State of Alabama   \n",
       "165     90749  1883.0                                   Bush v. Kentucky   \n",
       "...       ...     ...                                                ...   \n",
       "1868  4174308  2017.0             Town of Chester v. Laroe Estates, Inc.   \n",
       "987   4154239  2017.0                                   Manuel v. Joliet   \n",
       "476   4151827  2017.0    Bethune-Hill v. Virginia State Bd. of Elections   \n",
       "2852  4181062  2017.0  Bristol-Myers Squibb Co. v. Superior Court of ...   \n",
       "88    4281072  2018.0  Masterpiece Cakeshop, Ltd. v. Colorado Civil R...   \n",
       "1     4285135  2018.0  Masterpiece Cakeshop, Ltd. v. Colorado Civil R...   \n",
       "87    4246856  2018.0                             Class v. United States   \n",
       "2554  4287784  2018.0                                    Abbott v. Perez   \n",
       "1989  4264598  2018.0                                 Sessions v. Dimaya   \n",
       "346   4287283  2018.0                                Currier v. Virginia   \n",
       "2057  4285391  2018.0                                   Gill v. Whitford   \n",
       "916   4288403  2018.0  National Institute of Family and Life Advocate...   \n",
       "4383  4281071  2018.0  Masterpiece Cakeshop, Ltd. v. Colorado Civil R...   \n",
       "227   4246354  2018.0                               Silvester v. Becerra   \n",
       "3287  4280797  2018.0  Masterpiece Cakeshop, Ltd. v. Colorado Civil R...   \n",
       "4405  4278950  2018.0                                Collins v. Virginia   \n",
       "2246  4251727  2018.0      U. S. Bank N. A. v. Village at Lakeridge, LLC   \n",
       "2948  4288893  2018.0    Janus v. State, County, and Municipal Employees   \n",
       "3702  4407339  2019.0        Virginia House of Delegates v. Bethune-Hill   \n",
       "269   4407340  2019.0        Manhattan Community Access Corp. v. Halleck   \n",
       "2673  4410205  2019.0  Tennessee Wine and Spirits Retailers Assn. v. ...   \n",
       "2044  4407520  2019.0                            Gamble v. United States   \n",
       "299   4369169  2019.0                                   Timbs v. Indiana   \n",
       "893   4407341  2019.0                            Gamble v. United States   \n",
       "1851  4373152  2019.0  Morris County Bd. of Chosen Freeholders v. Fre...   \n",
       "409   4410722  2019.0                              Rucho v. Common Cause   \n",
       "4003  4371672  2019.0                                     Garza v. Idaho   \n",
       "1405  4407521  2019.0                            Gamble v. United States   \n",
       "738   4400867  2019.0                                 Nieves v. Bartlett   \n",
       "1807  4368899  2019.0                                                NaN   \n",
       "\n",
       "                                                corpora  \n",
       "1523  wall worthyvthe commissionerssupreme court uni...  \n",
       "1789  wall osbornvnicholson et alsupreme court unite...  \n",
       "3851  wall bradwellvthe statesupreme court united st...  \n",
       "725   wall slaughter-house casesthe butcher benevole...  \n",
       "250   wall bartemeyerviowasupreme court united state...  \n",
       "2508  wall minorvhappersettsupreme court united stat...  \n",
       "1045  wall scholeyvrewsupreme court united state mr ...  \n",
       "3904  raymondvthomassupreme court united statesmr p ...  \n",
       "4491  walkervsauvinetsupreme court united state mr c...  \n",
       "422   united statesvreese et alsupreme court united ...  \n",
       "1364  united statesvcruikshank et alsupreme court un...  \n",
       "2254  mcmillenvandersonsupreme court united state mr...  \n",
       "1485  munnvillinoissupreme court united state mr wc ...  \n",
       "92    keithvclarksupreme court united statesmr phili...  \n",
       "900   pennoyervneffsupreme court united state mr wf ...  \n",
       "4161  robertsonvceasesupreme court united state mr h...  \n",
       "3938  davidsonvnew orleanssupreme court united state...  \n",
       "1181  hallvdecuirsupreme court united state mr rh ma...  \n",
       "3333  straudervwest virginiasupreme court united sta...  \n",
       "1422  ct l ed city nat bank ft worth april applicati...  \n",
       "4219  missourivlewissupreme court united state mr je...  \n",
       "1288  ex parte virginiasupreme court united state mr...  \n",
       "2161  virginiavrivessupreme court united state mr ja...  \n",
       "4397  nealvdelawaresupreme court united state mr cha...  \n",
       "4177  grossvunited state mortgage companysupreme cou...  \n",
       "1317  state louisiana ex rel folsomvmayor administra...  \n",
       "1000  united statesvgale anothersupreme court united...  \n",
       "274   united statesvharrissupreme court united state...  \n",
       "3343  ct l ed pacevstate alabamajanuary section code...  \n",
       "165   bushvkentuckysupreme court united statesmr lle...  \n",
       "...                                                 ...  \n",
       "1868  slip opinion october term syllabus note feasib...  \n",
       "987   slip opinion october term syllabus note feasib...  \n",
       "476   slip opinion october term syllabus note feasib...  \n",
       "2852  slip opinion october term syllabus note feasib...  \n",
       "88    slip opinion october term syllabus note feasib...  \n",
       "1     summary difference exist document new document...  \n",
       "87    slip opinion october term syllabus note feasib...  \n",
       "2554  slip opinion october term syllabus note feasib...  \n",
       "1989  slip opinion october term syllabus note feasib...  \n",
       "346   slip opinion october term syllabus note feasib...  \n",
       "2057  slip opinion october term syllabus note feasib...  \n",
       "916   slip opinion october term syllabus note feasib...  \n",
       "4383  summary pm difference exist document new docum...  \n",
       "227   cite u thomas j dissentingsupreme court united...  \n",
       "3287  slip opinion october term syllabus note feasib...  \n",
       "4405  slip opinion october term syllabus note feasib...  \n",
       "2246  slip opinion october term syllabus note feasib...  \n",
       "2948  slip opinion october term syllabus note feasib...  \n",
       "3702  slip opinion october term syllabus note feasib...  \n",
       "269   slip opinion october term syllabus note feasib...  \n",
       "2673  slip opinion october term syllabus note feasib...  \n",
       "2044  pm compare result old file new file - pdf - ne...  \n",
       "299   slip opinion october term syllabus note feasib...  \n",
       "893   slip opinion october term syllabus note feasib...  \n",
       "1851  cite u kavanaugh statement k j dissent avanaug...  \n",
       "409   slip opinion october term syllabus note feasib...  \n",
       "4003  slip opinion october term syllabus note feasib...  \n",
       "1405  slip opinion october term syllabus note feasib...  \n",
       "738   slip opinion october term syllabus note feasib...  \n",
       "1807  cite u thomas j concurringsupreme court united...  \n",
       "\n",
       "[4579 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit method creates bag of words. See them with .get_feature_names()\n",
    "# This returns a sparse matrix. For a dense matrix, you could perform:\n",
    "# pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "# Create a bag of words using ngrams up to 3 words long\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow(df_col):\n",
    "    #custom_vec = CountVectorizer(ngram_range=(1,3))\n",
    "    custom_vec = CountVectorizer(stop_words, strip_accents=\"unicode\")\n",
    "    corpora = df_col.values.flatten().tolist()\n",
    "    wm = custom_vec.fit_transform(corpora)\n",
    "    vocab = custom_vec.vocabulary_\n",
    "    tokens = custom_vec.get_feature_names()\n",
    "    #df = wm_to_df(wm, tokens)\n",
    "    \n",
    "    return wm, tokens, vocab #df, tokens\n",
    "# Create the matrix and get the features and vocab on the whole corpus\n",
    "wordmatrix, features, vocab = make_bow(corp['corpora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of bag of words vocabulary\n",
    "def bow_df(vocab):\n",
    "    vocab_values = list(vocab.values())\n",
    "    vocab_keys = list(vocab.keys())\n",
    "    count_df = pd.DataFrame(list(zip(vocab_keys,vocab_values)))\n",
    "    count_df.columns = ['Word', 'Count']\n",
    "    count_df.sort_values(by='Count', ascending=False, inplace=True)\n",
    "    return count_df\n",
    "\n",
    "# count_df = bow_df(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Latent Semantic Analysis on the corpus as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a pipeline to perform LSA\n",
    "## Create a vectorizer to convert raw documents to TF/IDF matrix\n",
    "#vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
    "#                             strip_accents=\"unicode\",\n",
    "#                             ngram_range=(1,2),\n",
    "#                             use_idf=True, \n",
    "#                             smooth_idf=True)\n",
    "#\n",
    "## This normalizes the vector (L2 norm of 1.0) to neutralize \n",
    "## the effect of document length on tf-idf.\n",
    "#\n",
    "#normalizer = Normalizer(copy=False)\n",
    "#\n",
    "## Perform singular value decomposition:\n",
    "## Project the tfidf vectors onto the first N principal components.\n",
    "#\n",
    "#svd_model = TruncatedSVD(n_components=100,         # number of dimensions\n",
    "#                         algorithm='randomized',\n",
    "#                         n_iter=10)\n",
    "#\n",
    "#lsa_transformer = Pipeline([('tfidf', vectorizer), \n",
    "#                            ('svd', svd_model),\n",
    "#                            ('norm', normalizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_transform(corpora):\n",
    "    lsa_matrix = lsa_transformer.fit_transform(corpora)\n",
    "    print(f\"tf-idf params: {lsa_transformer.steps[0][1].get_params()}\")\n",
    "\n",
    "    # Get the words that correspond to each of the features.\n",
    "    feat_names = lsa_transformer.steps[0][1].get_feature_names()\n",
    "    vocab = lsa_transformer.steps[0][1].vocabulary_\n",
    "    \n",
    "    # Plot the top 10 terms for each top-10 LSA component. \n",
    "    for component_num in range(0, 10): # i.e., the top 10 components.\n",
    "    \n",
    "        comp = lsa_transformer.steps[1][1].components_[component_num]\n",
    "        \n",
    "        # Sort the weights in the first component and get indices\n",
    "        indices = np.argsort(comp).tolist()\n",
    "        \n",
    "        # Reverse order (largest weights first)\n",
    "        indices.reverse()\n",
    "        \n",
    "        # Get top 10 terms for each component        \n",
    "        terms = [feat_names[weight_index] for weight_index in indices[0:10]]    \n",
    "        weights = [comp[weight_index] for weight_index in indices[0:10]]    \n",
    "       \n",
    "        # Display these terms and their weights as a horizontal bar graph.    \n",
    "        # The horizontal bar graph displays the first item on the bottom; reverse\n",
    "        # the order of the terms so the biggest one is on top.\n",
    "        terms.reverse()\n",
    "        weights.reverse()\n",
    "        positions = np.arange(10) + .5    # Center the bar on the y axis.\n",
    "        \n",
    "        plt.figure(component_num)\n",
    "        plt.barh(positions, weights, align=\"center\")\n",
    "        plt.yticks(positions, terms)\n",
    "        plt.xlabel(\"Weight\")\n",
    "        plt.title(f\"Strongest terms for component {component_num+1}\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"terms_for_component_{component_num+1}\")\n",
    "        plt.show()\n",
    "    \n",
    "    return lsa_matrix, feat_names, vocab\n",
    "\n",
    "# lsa_matrix, feat_names, lsa_vocab = lsa_transform(corp['corpora'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year ranges and bin the data accordingly.\n",
    "# To track evolution over time, the cases will be binned\n",
    "# in a rolling fashion, with overlap, to smooth out\n",
    "# the effects of the groupings. \n",
    "\n",
    "# ------------------------\n",
    "\n",
    "# Include left, exclude right; half-closed, half-open interval [a, b)\n",
    "# cf. pandas rolling() function\n",
    "\n",
    "def build_year_ranges(overlap, first=1785, last=2019, increment=20):\n",
    "    # assert: bin cannot be underfull; overlap shouldn't exceed smallest bin size. \n",
    "    # max increment // 2 is a guideline. \n",
    "    # rewrite this as a class.\n",
    "    # overlap = max(overlap, increment // 2)\n",
    "    year_ranges = []\n",
    "    for n in range(first, last, overlap):\n",
    "        year_ranges.append((n, n + increment))\n",
    "    return year_ranges\n",
    "\n",
    "# warning: years must have the same index as data\n",
    "def put_data_under_year_ranges(data, years, year_ranges):\n",
    "\n",
    "    # assert len(data) == len(years), \\\n",
    "    # \"get_content_under_ranges: data and years do not match length\"\n",
    "\n",
    "    # build a dict with keys = year_ranges, with a list for each range\n",
    "    data_ranges = defaultdict(list)\n",
    "    \n",
    "    # bin all the data by range - each row should fall in two bins, \n",
    "    # if ranges are cleanly overlapped\n",
    "\n",
    "    # if data is a list\n",
    "    for i in range(len(data)):\n",
    "        for y in year_ranges:\n",
    "            if y[0] <= years[i] and years[i] < y[1]:\n",
    "                data_ranges[y].append(data[i]) # for dictionary\n",
    "                \n",
    "                # this should happen twice for every entry except \n",
    "                # the very oldest and the very newest\n",
    "    return data_ranges\n",
    "# ------------\n",
    "# main\n",
    "              \n",
    "# bins = build_year_ranges(first_year, last_year, increment, overlap)\n",
    "# binned_data = put_data_under_year_ranges(cases, years, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame columns to lists (warning: keep indices aligned, \n",
    "# and make sure cases are sorted by year)\n",
    "\n",
    "corp_list = corp[\"corpora\"].values.flatten().tolist()\n",
    "year_list = corp[\"year\"].values.flatten().tolist()\n",
    "names_list = corp[\"case_name\"].values.flatten().tolist()\n",
    "id_list = corp[\"id_x\"].values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array for all cases \n",
    "# in the format array[name][text]\n",
    "\n",
    "case_dict = np.array(list(zip(names_list, corp_list)))\n",
    "\n",
    "# Get all case texts: case_dict[:,1]\n",
    "# Get all case names: case_dict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire corpus with ids\n",
    "case_14 = np.array(list(zip(id_list, corp_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_ranges = build_year_ranges(overlap=5, first=1860, last=2019, increment=20)\n",
    "# binned_data = put_data_under_year_ranges(corp_list, year_list, year_ranges) # dict of lists\n",
    "binned_data = put_data_under_year_ranges(case_dict, year_list, year_ranges) # dict of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_k = list(binned_data.keys())\n",
    "values_v = [len(v) for v in binned_data.values()]\n",
    "num_cases = list(zip(years_k, values_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases decided circa (1860, 1880): 18\n",
      "Number of cases decided circa (1865, 1885): 39\n",
      "Number of cases decided circa (1870, 1890): 80\n",
      "Number of cases decided circa (1875, 1895): 142\n",
      "Number of cases decided circa (1880, 1900): 226\n",
      "Number of cases decided circa (1885, 1905): 344\n",
      "Number of cases decided circa (1890, 1910): 460\n",
      "Number of cases decided circa (1895, 1915): 579\n",
      "Number of cases decided circa (1900, 1920): 710\n",
      "Number of cases decided circa (1905, 1925): 761\n",
      "Number of cases decided circa (1910, 1930): 771\n",
      "Number of cases decided circa (1915, 1935): 729\n",
      "Number of cases decided circa (1920, 1940): 648\n",
      "Number of cases decided circa (1925, 1945): 576\n",
      "Number of cases decided circa (1930, 1950): 537\n",
      "Number of cases decided circa (1935, 1955): 488\n",
      "Number of cases decided circa (1940, 1960): 443\n",
      "Number of cases decided circa (1945, 1965): 505\n",
      "Number of cases decided circa (1950, 1970): 602\n",
      "Number of cases decided circa (1955, 1975): 877\n",
      "Number of cases decided circa (1960, 1980): 1170\n",
      "Number of cases decided circa (1965, 1985): 1380\n",
      "Number of cases decided circa (1970, 1990): 1499\n",
      "Number of cases decided circa (1975, 1995): 1324\n",
      "Number of cases decided circa (1980, 2000): 1033\n",
      "Number of cases decided circa (1985, 2005): 747\n",
      "Number of cases decided circa (1990, 2010): 480\n",
      "Number of cases decided circa (1995, 2015): 364\n",
      "Number of cases decided circa (2000, 2020): 331\n",
      "Number of cases decided circa (2005, 2025): 227\n",
      "Number of cases decided circa (2010, 2030): 150\n",
      "Number of cases decided circa (2015, 2035): 71\n"
     ]
    }
   ],
   "source": [
    "for k,v in binned_data.items():\n",
    "    print(f\"Number of cases decided circa {k}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a dictionary comprehension to convert a list of lists\n",
    "# to a numpy array for easier access to values\n",
    "\n",
    "binned_data = {k: np.asarray(v) for k,v in binned_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open (\"binned_data.pik\", \"wb\") as bdf:\n",
    "#    dill.dump(binned_data, bdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hoverlabel": {
          "namelength": 0
         },
         "hovertemplate": "Years=%{x}<br>Approx. No. Opinions Issued=%{y}",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          1870,
          1875,
          1880,
          1885,
          1890,
          1895,
          1900,
          1905,
          1910,
          1915,
          1920,
          1925,
          1930,
          1935,
          1940,
          1945,
          1950,
          1955,
          1960,
          1965,
          1970,
          1975,
          1980,
          1985,
          1990,
          1995,
          2000,
          2005,
          2010,
          2015,
          2020,
          2025
         ],
         "xaxis": "x",
         "y": [
          18,
          39,
          80,
          142,
          226,
          344,
          460,
          579,
          710,
          761,
          771,
          729,
          648,
          576,
          537,
          488,
          443,
          505,
          602,
          877,
          1170,
          1380,
          1499,
          1324,
          1033,
          747,
          480,
          364,
          331,
          227,
          150,
          71
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.98
         ],
         "title": {
          "text": "Years"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Approx. No. Opinions Issued"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"cee5d3b7-7947-4839-aed6-832a2fc562c6\" class=\"plotly-graph-div\" style=\"height:600px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"cee5d3b7-7947-4839-aed6-832a2fc562c6\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'cee5d3b7-7947-4839-aed6-832a2fc562c6',\n",
       "                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Years=%{x}<br>Approx. No. Opinions Issued=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [1870.0, 1875.0, 1880.0, 1885.0, 1890.0, 1895.0, 1900.0, 1905.0, 1910.0, 1915.0, 1920.0, 1925.0, 1930.0, 1935.0, 1940.0, 1945.0, 1950.0, 1955.0, 1960.0, 1965.0, 1970.0, 1975.0, 1980.0, 1985.0, 1990.0, 1995.0, 2000.0, 2005.0, 2010.0, 2015.0, 2020.0, 2025.0], \"xaxis\": \"x\", \"y\": [18, 39, 80, 142, 226, 344, 460, 579, 710, 761, 771, 729, 648, 576, 537, 488, 443, 505, 602, 877, 1170, 1380, 1499, 1324, 1033, 747, 480, 364, 331, 227, 150, 71], \"yaxis\": \"y\"}],\n",
       "                        {\"barmode\": \"relative\", \"height\": 600, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.98], \"title\": {\"text\": \"Years\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Approx. No. Opinions Issued\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cee5d3b7-7947-4839-aed6-832a2fc562c6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_df = pd.DataFrame(num_cases)\n",
    "num_df.columns = [\"Years\", \"Approx. No. Opinions Issued\"]\n",
    "num_df.Years = num_df.Years.apply(lambda x: (x[0]+x[1])/2)\n",
    "fig = px.bar(num_df, x='Years', y='Approx. No. Opinions Issued')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite to use only binned_data keys\n",
    "# need an assert statement to handle edge cases of too-small buckets\n",
    "# make rolling a class\n",
    "\n",
    "def LSA_per_bin(corpora, ngrams=(1,2), ntop=50):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words=stop_words,\n",
    "                             strip_accents=\"unicode\",\n",
    "                             ngram_range=ngrams,\n",
    "                             use_idf=True, \n",
    "                             smooth_idf=True)\n",
    "\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    svd_model = TruncatedSVD(n_components=100,         \n",
    "                         algorithm='randomized',\n",
    "                         n_iter=10)\n",
    "\n",
    "    lsa_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                                ('svd', svd_model),\n",
    "                                ('norm', normalizer)])\n",
    "    \n",
    "    # assert: first pipeline component must be tfidf/count vectorizer\n",
    "    lsa_matrix = lsa_transformer.fit_transform(corpora)\n",
    "\n",
    "    # Get the words that correspond to each of the features.\n",
    "    feat_names = lsa_transformer.steps[0][1].get_feature_names()\n",
    "    vocab = lsa_transformer.steps[0][1].vocabulary_\n",
    "\n",
    "    \n",
    "    ceiling = min(len(corpora), ntop)\n",
    "    for component_num in range(0, ceiling):\n",
    "    \n",
    "        comp = lsa_transformer.steps[1][1].components_[component_num]\n",
    "        \n",
    "        # Sort the weights in the first component and get indices\n",
    "        indices = np.argsort(comp).tolist()\n",
    "        \n",
    "        # Reverse order (largest weights first)\n",
    "        indices.reverse()\n",
    "        \n",
    "        # Get top 10 terms for component        \n",
    "        terms = [feat_names[weight_index] for weight_index in indices[0:ceiling]]    \n",
    "        weights = [comp[weight_index] for weight_index in indices[0:ceiling]] \n",
    "        terms.reverse()\n",
    "        weights.reverse()\n",
    "        \n",
    "        bin_terms = terms\n",
    "        bin_weights = weights\n",
    "        bin_matrix = lsa_matrix\n",
    "        bin_feat_names = feat_names\n",
    "        bin_vocab = vocab\n",
    "        \n",
    "        for component_num in range(0, 10): # i.e., the top 10 components.\n",
    "    \n",
    "        comp = lsa_transformer.steps[1][1].components_[component_num]\n",
    "        \n",
    "        # Sort the weights in the first component and get indices\n",
    "        indices = np.argsort(comp).tolist()\n",
    "        \n",
    "        # Reverse order (largest weights first)\n",
    "        indices.reverse()\n",
    "        \n",
    "        # Get top 10 terms for each component        \n",
    "        terms = [feat_names[weight_index] for weight_index in indices[0:10]]    \n",
    "        weights = [comp[weight_index] for weight_index in indices[0:10]]    \n",
    "       \n",
    "        # Display these terms and their weights as a horizontal bar graph.    \n",
    "        # The horizontal bar graph displays the first item on the bottom; reverse\n",
    "        # the order of the terms so the biggest one is on top.\n",
    "        terms.reverse()\n",
    "        weights.reverse()\n",
    "        positions = np.arange(10) + .5    # Center the bar on the y axis.\n",
    "        \n",
    "        plt.figure(component_num)\n",
    "        plt.barh(positions, weights, align=\"center\")\n",
    "        plt.yticks(positions, terms)\n",
    "        plt.xlabel(\"Weight\")\n",
    "        plt.title(f\"Strongest terms for component {component_num+1}\")\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"terms_for_component_{component_num+1}\")\n",
    "        plt.show()\n",
    "        \n",
    "    return {\"terms\": bin_terms, \"weights\": bin_weights, \"matrix\": bin_matrix, \n",
    "            \"feat_names\": bin_feat_names, \"vocab\": bin_vocab}\n",
    "        \n",
    "def rolling_LSA(binned_data):    # (binned_data, year_ranges)\n",
    "    \n",
    "    model_ranges = defaultdict(dict)\n",
    "    \n",
    "    for y in tqdm_notebook(binned_data.keys()): # keys must be year ranges\n",
    "        model_ranges[y] = LSA_per_bin(binned_data[y][:,1]) # [:,1] needed only if binned_data is np.array. \n",
    "                                                           # use .append() instead of = if model_ranges is dict \n",
    "                                                           # as opposed to defaultdict\n",
    "        print(f\"Running cases from: {y}\") \n",
    "        \n",
    "    return model_ranges    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c0217da40d4d61ad4c5e83cb839881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cases from: (1860, 1880)\n",
      "Running cases from: (1870, 1890)\n",
      "Running cases from: (1880, 1900)\n",
      "Running cases from: (1890, 1910)\n",
      "Running cases from: (1900, 1920)\n",
      "Running cases from: (1910, 1930)\n",
      "Running cases from: (1920, 1940)\n",
      "Running cases from: (1930, 1950)\n",
      "Running cases from: (1940, 1960)\n",
      "Running cases from: (1950, 1970)\n",
      "Running cases from: (1960, 1980)\n",
      "Running cases from: (1970, 1990)\n",
      "Running cases from: (1980, 2000)\n",
      "Running cases from: (1990, 2010)\n",
      "Running cases from: (2000, 2020)\n",
      "Running cases from: (2010, 2030)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsa = rolling_LSA(binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_terms(lsa):\n",
    "    for k,v in lsa.items():\n",
    "        print(f\"Top terms for {k}:\\n{lsa[k]['terms']}\") \n",
    "          \n",
    "# N.B.: Proper indexing is lsa[k][0]['terms'] if model_ranges is dict rather than defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for (1860, 1880):\n",
      "['section', 'prerequisite', 'stock', 'slaughter houses', 'houses', 'immunity', 'cattle', 'privilege immunity', 'slavery', 'monopoly', 'animal', 'city', 'corporation', 'exclusive', 'exclusive privilege', 'citizen', 'slaughter', 'privilege']\n",
      "Top terms for (1870, 1890):\n",
      "['nuisance', 'gas', 'safety', 'care', 'voter', 'year', 'tax claimed', 'military code', 'qualification', 'grain', 'denies equal', 'conduct business', 'special character', 'clause fourteenth', 'treat alike', 'use steam', 'suffrage', 'railroad corporation', 'intoxicate liquor', 'legislation special', 'berry', 'berry saunders', 'injustice', 'use', 'military', 'intoxicate', 'property', 'liability impose', 'contention', 'injury subsequently', 'hardship', 'legislation', 'employment immediate', 'wrong negligence', 'kind legislation', 'immediate direction', 'instance kind', 'militia', 'election', 'member congress', 'vote', 'kansa', 'servant', 'negligence', 'hardship injustice', 'liquor', 'incompetency', 'yarbrough', 'negligence incompetency', 'liability']\n",
      "Top terms for (1880, 1900):\n",
      "['reputation', 'fee', 'cause action', 'purchaser', 'inspection', 'suit', 'execution', 'damage', 'washington', 'validity', 'office', 'deposit', 'relators', 'practise', 'year', 'lease', 'brought', 'sum', 'money', 'jury', 'payment', 'association', 'assessment', 'saint louis', 'new', 'cherokee nation', 'owner', 'coupon', 'certificate', 'plea', 'saint', 'transfer', 'provide', 'employes', 'division number', 'bar', 'cherokee', 'recover', 'insanity', 'bobb', 'nation', 'commerce', 'constitution', 'capital', 'action', 'section', 'limitation', 'license', 'remedy', 'division']\n",
      "Top terms for (1890, 1910):\n",
      "['levee', 'chicago', 'milk', 'non resident', 'compensation', 'plank', 'improvement', 'notice', 'dog', 'dam', 'illinois', 'butter', 'contract', 'inheritance tax', 'publication', 'pennsylvania', 'snell', 'amendment', 'navigable', 'cost', 'council', 'grant', 'mortgage', 'cause', 'judge', 'legacy', 'dollar', 'earnings', 'virginia', 'labor', 'resident', 'immunity', 'ordinance', 'franchise', 'division', 'oleomargarine', 'garbage', 'motion', 'privilege', 'succession', 'jury', 'alien', 'suit', 'land', 'transfer', 'chinese', 'inheritance', 'road', 'charter', 'toll']\n",
      "Top terms for (1900, 1920):\n",
      "['practice', 'division', 'interstate', 'transportation', 'freight', 'indian', 'health', 'shipment', 'common', 'south carolina', 'indiana', 'non', 'south', 'stockholder', 'deed', 'new', 'west', 'grand', 'loss damage', 'virginia', 'common carrier', 'income', 'northern', 'intrastate', 'witness', 'jurisdiction', 'charter', 'stock', 'wisconsin', 'trust', 'traffic', 'track', 'expense', 'cow', 'west virginia', 'business', 'certificate', 'commerce', 'council', 'resident', 'treaty', 'railroad', 'cost', 'city', 'disfigurement', 'bullen', 'circuit', 'combination', 'carrier', 'milk']\n",
      "Top terms for (1910, 1930):\n",
      "['crime', 'bullen', 'employment', 'cent', 'board equalization', 'interstate', 'commerce', 'convict', 'syndicalism', 'wisconsin', 'claimant', 'weight', 'attorney fee', 'zone', 'passenger', 'arizona', 'village', 'appeal virginia', 'bread', 'loan', 'membership', 'labor', 'mayor', 'package', 'milk', 'ohio', 'alien', 'premium', 'loaf', 'philippine', 'ordinance', 'water', 'commission', 'fee', 'motor vehicle', 'assessment', 'motor', 'gasoline', 'punishment', 'bridge', 'foot', 'highway', 'west', 'policy', 'contract', 'vehicle', 'county', 'west virginia', 'canal', 'virginia']\n",
      "Top terms for (1920, 1940):\n",
      "['faith credit', 'pipe line', 'mile', 'drainage', 'railway kentucky', 'southern railway', 'minimum wage', 'officer', 'tobacco', 'appointment', 'paid', 'station', 'tank', 'writ', 'service', 'nebraska', 'mileage', 'village', 'cost', 'railway', 'weight measure', 'compensation', 'baker', 'secretary', 'storage', 'ounce', 'trustee', 'association', 'attorney', 'woman', 'use', 'mayor', 'dakota', 'north dakota', 'massachusetts', 'minimum', 'tolerance', 'north', 'pound', 'gin', 'trust', 'fund', 'wage', 'bread', 'commonwealth', 'gasoline', 'loaf', 'kentucky', 'weight', 'california']\n",
      "Top terms for (1930, 1950):\n",
      "['telephone', 'store', 'excess condemnation', 'violence', 'citizen', 'retirement', 'unlawful assemblage', 'trial', 'privilege immunity', 'bankruptcy', 'reserve', 'panel', 'concert', 'depreciation charge', 'faith credit', 'expense', 'assemblage', 'intoxicate liquor', 'intoxicate', 'railroad', 'liquor control', 'nevada', 'wyoming', 'charge', 'new jersey', 'bond', 'immunity', 'gas', 'oklahoma', 'beer', 'divorce', 'jersey', 'indiana', 'citizenship', 'caravan', 'trust', 'cost', 'domicile', 'arkansas', 'michigan', 'trustee', 'texas', 'carrier', 'jury', 'suit', 'license', 'fee', 'illinois', 'depreciation', 'liquor']\n",
      "Top terms for (1940, 1960):\n",
      "['barsky', 'time', 'north', 'talk', 'grand jury', 'art', 'los angeles', 'const art', 'michigan', 'deputy', 'told', 'bank', 'american express', 'angeles', 'blood', 'vehicle', 'grand', 'const', 'organization', 'list', 'los', 'yes', 'search', 'regent', 'murder', 'new jersey', 'jersey', 'cong', 'trial', 'sacrilege', 'jeopardy', 'county', 'california', 'highway', 'investigation', 'picket', 'subversive', 'new hampshire', 'hampshire', 'death', 'license', 'religious', 'attorney', 'money order', 'nt', 'indiana', 'alabama', 'committee', 'church', 'sheriff']\n",
      "Top terms for (1950, 1970):\n",
      "['wmca', 'addiction', 'sacrilege', 'reasonable', 'person', 'report', 'rate', 'brotherhood', 'carrier', 'restaurant', 'association', 'drug', 'crime', 'order', 'judge', 'literacy', 'general church', 'officer', 'suspension', 'inspection', 'film', 'sanity', 'mental', 'lomenzo', 'marihuana', 'defendant', 'race', 'virginia', 'blood', 'housing', 'russian', 'record', 'addict', 'probable cause', 'racial', 'union', 'ohio', 'corporation', 'transcript', 'deportation', 'new', 'railroad', 'insanity', 'insane', 'narcotic', 'juvenile', 'plan', 'commission', 'alien', 'church']\n",
      "Top terms for (1960, 1980):\n",
      "['material', 'unemployment', 'prejudice', 'yacht', 'miranda', 'obscenity', 'english', 'constitutional', 'vii', 'facility', 'juror', 'police', 'virginia', 'labor', 'park', 'ohio', 'apportionment', 'alaska', 'class', 'mentally ill', 'abstention', 'sunday', 'racial', 'employee', 'commitment', 'employment', 'title vii', 'mentally', 'commonwealth puerto', 'judge', 'question', 'lawyer', 'mental', 'restaurant', 'forfeiture', 'spanish', 'contempt', 'identification', 'appellees', 'union', 'commonwealth', 'new', 'county', 'hospital', 'indian', 'puerto rican', 'rican', 'puerto rico', 'rico', 'puerto']\n",
      "Top terms for (1970, 1990):\n",
      "['pending', 'fourth amendment', 'edward', 'civilian', 'criminal prosecution', 'land', 'bruton', 'woman', 'government', 'direct review', 'incrimination', 'parole', 'compensation', 'attorney', 'retroactive', 'jury', 'batson', 'school', 'fifth', 'congress', 'sixth', 'declaratory', 'stay', 'new jersey', 'offense', 'jersey', 'ocallahan', 'sixth amendment', 'challenge', 'fifth amendment', 'use peremptory', 'employee', 'privilege', 'injunction', 'counsel', 'search', 'swain', 'mitigate', 'applicant', 'retroactivity', 'criminal', 'veteran', 'prosecution', 'immunity', 'martial', 'new', 'confession', 'military', 'peremptory challenge', 'peremptory']\n",
      "Top terms for (1980, 2000):\n",
      "['baldasar', 'population', 'indian', 'corporation', 'convict', 'consent decree', 'ohio', 'self', 'isaac', 'sign', 'unitary', 'defendant', 'deprivation', 'property', 'tribal', 'decree', 'mitigate', 'procedural', 'unitary business', 'tenant', 'privilege', 'defense', 'food stamp', 'speech', 'business', 'misdemeanor', 'default', 'grand jury', 'felony', 'imprisonment', 'grand', 'jury', 'mitigate circumstance', 'illinois', 'household', 'apportionment', 'confession', 'parent', 'uncounseled', 'asarco', 'ordinance', 'self defense', 'habeas', 'notice', 'process', 'census', 'offense', 'income', 'conviction', 'cable']\n",
      "Top terms for (1990, 2010):\n",
      "['political', 'gender based', 'medication', 'establishment clause', 'assisted suicide', 'stereotype', 'crime', 'explanation', 'paternity', 'inference', 'california', 'attorney fee', 'factor', 'defendant', 'award', 'parent', 'facie', 'employer', 'prima facie', 'new', 'prima', 'property', 'cruzan', 'mother', 'county', 'child', 'prison', 'evidence', 'apprendi', 'plra', 'citizenship', 'visitation', 'immunity', 'employee', 'assist suicide', 'father', 'speech', 'family leave', 'inmate', 'family', 'gender', 'retroactivity', 'patient', 'fmla', 'leave', 'teague', 'batson', 'prosecutor', 'suicide', 'fee']\n",
      "Top terms for (2000, 2020):\n",
      "['initiative', 'county', 'student', 'martinez', 'dna test', 'bartlett', 'gamble', 'howard', 'relief', 'storch', 'mcmillan', 'lpo', 'cone', 'retaliatory arrest', 'probable', 'chavez', 'monell', 'osborne', 'mcintyre', 'probable cause', 'hartman', 'dna', 'arizona', 'jury', 'vote', 'birth', 'taking', 'ballot', 'hotel', 'unwed', 'election', 'citizenship', 'morales santana', 'santana', 'circuit', 'morales', 'arrest', 'mother', 'referendum', 'ninth circuit', 'ayala', 'ninth', 'apprendi', 'father', 'retaliatory', 'fee', 'parent', 'visitation', 'voter', 'child']\n",
      "Top terms for (2010, 2030):\n",
      "['racial', 'groom policy', 'defamation', 'successive', 'cc', 'inn', 'prayer', 'privilege', 'clearly establish', 'lobby', 'gertz', 'hobby lobby', 'hobby', 'hhs', 'initiative', 'second amendment', 'agent', 'amendment', 'mckee', 'wait', 'counsel', 'bear arm', 'second successive', 'inference', 'phase', 'penalty', 'kentucky', 'rickard', 'inch beard', 'inch', 'inference instruction', 'mitchell', 'midazolam', 'woodall', 'contempt', 'estelle', 'penalty phase', 'protester', 'magwood', 'insanity', 'wait period', 'storch', 'adverse inference', 'rfra', 'idaho', 'libel', 'garza', 'rluipa', 'juror', 'beard']\n"
     ]
    }
   ],
   "source": [
    "show_top_terms(lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal # of clusters for whole 14th corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm_notebook\n",
    "distorsions = []\n",
    "sil_scores = []\n",
    "k_max = 25\n",
    "vectorizer = TfidfVectorizer(max_df=0.95,\n",
    "                                     min_df=1, ngram_range=(1,2),\n",
    "                                     stop_words=stop_words,\n",
    "                                     strip_accents=\"unicode\",\n",
    "                                     use_idf=True, smooth_idf=True)\n",
    "\n",
    "#vz = vectorizer.fit_transform(corpora)\n",
    "\n",
    "for k in tqdm_notebook(range(2, k_max)):\n",
    "    kmeans_model = MiniBatchKMeans(n_clusters=k, init='k-means++', n_init=1, random_state=42,  \n",
    "                         init_size=500, verbose=True, max_iter=1000)\n",
    "    #kmeans_model.fit(vz)\n",
    "    \n",
    "    km_transformer = Pipeline([('tfidf', vectorizer), \n",
    "                            ('km', kmeans_model),\n",
    "                            ('norm', normalizer)])\n",
    "    \n",
    "    km = km_transformer.fit_transform(case_dict[:,1])\n",
    "    \n",
    "    # sil_score = silhouette_score(vz, kmeans_model.labels_)\n",
    "    sil_score = silhouette_score(km, km_transformer.steps[1][1].labels_)\n",
    "    sil_scores.append(sil_score)\n",
    "    # distorsions.append(kmeans_model.inertia_)\n",
    "    distorsions.append(km_transformer.steps[1][1].inertia_)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(15, 10))\n",
    "\n",
    "ax1.plot(range(2, k_max), distorsions)\n",
    "ax1.set_title('Distorsion vs num of clusters')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(range(2, k_max), sil_scores)\n",
    "ax2.set_title('Silhouette score vs num of clusters')\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(corpora, n_clusters=8, ngrams=(1,2)):\n",
    "    print(f\"{len(corpora)} documents\")\n",
    "    \n",
    "    print(\"Extracting features from the training dataset \"\n",
    "          \"using a sparse vectorizer\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_df=0.95,\n",
    "                                     min_df=1, ngram_range=ngrams,\n",
    "                                     stop_words=stop_words,\n",
    "                                     use_idf=True)\n",
    "    km = MiniBatchKMeans(n_clusters=n_clusters, init='k-means++', n_init=100,\n",
    "                             init_size=500, batch_size=1000)\n",
    "    X = vectorizer.fit_transform(corpora)\n",
    "    \n",
    "    \n",
    "    print(f\"done in {(time.time() - t0)}\")\n",
    "    print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    print(f\"Clustering sparse data with {km}\")\n",
    "    t0 = time.time()\n",
    "    km.fit(X)\n",
    "    print(f\"done in {(time.time() - t0)}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    print(f\"Silhouette Coefficient: {silhouette_score(X, km.labels_)}\") # sample size=5000\n",
    "    \n",
    "    print()\n",
    "    print(f\"Top terms per cluster:\")\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    \n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(n_clusters):\n",
    "        print(f\"Cluster {i}:\")\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(f'{terms[ind]}')\n",
    "            print()       \n",
    "    \n",
    "    \n",
    "    clusters = {}\n",
    "    for i in range(n_clusters):\n",
    "        clusters[i] = []\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            clusters[i].append(terms[ind])\n",
    "    clusters[\"labels\"] = km.labels_\n",
    "    clusters[\"vocab\"] = vectorizer.vocabulary_\n",
    "    clusters[\"matrix\"] = X\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "def rolling_kmeans(binned_data, n_clusters=8, ngrams=(1,2)):    # (binned_data, year_ranges)\n",
    "    \n",
    "    model_ranges = defaultdict(dict)\n",
    "    \n",
    "    for y in tqdm_notebook(binned_data.keys()): # keys must be year ranges\n",
    "        model_ranges[y] = kmeans_cluster(binned_data[y][:,1], n_clusters, ngrams)\n",
    "                                                        # [:,1] needed only if binned_data is np.array. \n",
    "                                                        # use .append() instead of = if model_ranges is dict \n",
    "                                                        # as opposed to defaultdict\n",
    "        print(f\"Running cases from: {y}\") \n",
    "        print()\n",
    "    \n",
    "    return model_ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K means analysis on the corpus as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_14 = kmeans_cluster(case_14[:,1], n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_df = cluster_14.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"14th_am_kmeans.pik\", \"wb\") as kfl:\n",
    "#    dill.dump(dict_to_df, kfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Export ###\n",
    "df_14 = pd.DataFrame(data={\"case_id\":case_14[:,0],\"name\":case_dict[:,0],\"topics\": dict_to_df[\"labels\"],\"year\":year_list})\n",
    "bins = list(range(1869, 2040, 20))\n",
    "df_14 = pd.DataFrame.from_dict(dict_to_df)\n",
    "df_14[\"bins\"] = pd.cut(x=df_14[\"year\"],bins=bins)\n",
    "\n",
    "# with open(\"bin_topic.pik\", \"wb\") as dfp:\n",
    "#    dill.dump(df_14, dfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform K means analysis with a rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmb = rolling_kmeans(binned_data, n_clusters=5, ngrams=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"14th_am_kmeans.pik\", \"rb\") as kfl:\n",
    "    cluster_14 = dill.load(kfl)\n",
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2).fit_transform(cluster_14[\"matrix\"].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X_embedded.pik\", \"wb\") as xfl:\n",
    "    dill.dump(X_embedded, xfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = X_embedded.T\n",
    "fig = go.Scatter(x=X_plot[0], y=X_plot[1], \n",
    "                   mode='markers', \n",
    "                   marker=dict(color=colors, \n",
    "                               colorscale=cmap,\n",
    "                               showscale=False,\n",
    "                               line=dict(color='black', width=1)))\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmb-2.pik', 'wb') as k:\n",
    "    dill.dump(kmb, k)\n",
    "#with open('lsa-2.pik', 'wb') as ll:\n",
    "#    dill.dump(lsa, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"kmb.pik\", \"rb\") as rk:\n",
    "#    kmb = dill.load(rk)\n",
    "#with open(\"lsa.pik\", \"rb\") as ll:\n",
    "#    lsa = dill.load(ll)\n",
    "#with open(\"binned_data.pik\", \"rb\") as bdk:\n",
    "#    binned_data = dill.load(bdk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all case names \n",
    "case_names = defaultdict(list)\n",
    "for k in binned_data.keys():\n",
    "    case_names[k].append(binned_data[k][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_add(kmb, data):\n",
    "    topic_add = defaultdict(list)\n",
    "    for k in kmb.keys():\n",
    "        topic_add[k].append(list(map(list, zip(data[k], kmb[k][\"labels\"]))))\n",
    "    return topic_add\n",
    "topic_and_data = topic_add(kmb, binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names only? names with corpora\n",
    "topic_and_data = topic_zip(kmb, binned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get geographic data from citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "na_cites = df[df.citations.isna()]\n",
    "\n",
    "USCITE = df.citations.str.findall(re.compile(r\"'reporter'\\: 'U\\.S\\.'\"))\n",
    "USCITE[USCITE.isna()] # df.iloc[1807]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"USR\"] = df.citations.str.findall(r\"\\'volume\\'\\:\\s(\\d{2,3})\\,\\s\\'reporter\\'\\:\\s\\'(U\\.S\\.)\\'\\,\\s\\'page\\'\\:\\s\\'(\\d{2,4})\\'\")\n",
    "df[\"USR\"].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df[\"USR\"].apply(lambda x: str(x[0]) + \"/\" + str(x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.citations.str.replace(r\"((?<=\\'volume\\'\\:\\s)(\\d{2,3}).*?(?<=\\'reporter\\'\\:\\s\\')(U\\.S\\.)(?=\\'\\,\\s\\'page\\'\\:\\s\\').*?(\\d{3})(?=\\'\\,))\", \n",
    "                                                       r\"\\2\\3\\4\", regex=True)\n",
    "\n",
    "#usrep = df.citations.str.extractall(r\"(\\d{2,3}U\\.S\\.\\d{2,4})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object oriented / classes for rolling, frequency dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import Parameter\n",
    "class RollingFunc:    \n",
    "    \n",
    "    def __init__(self, function, binned_data, **kwargs):\n",
    "        self.model_ranges = defaultdict(dict)\n",
    "        self.binned_data = binned_data\n",
    "        self.function = function\n",
    "        for k in kwargs.keys():\n",
    "            if k in get_kwargs(self.function):\n",
    "                # self.__setattr__(k, kwargs[k]) set FUNCTION attr\n",
    "                \n",
    "    def get_kwargs(function):\n",
    "        \"\"\"Get names of callable arguments.\n",
    "\n",
    "        Special arguments (like ``*args`` and ``**kwargs``) are not included into\n",
    "        output.\n",
    "\n",
    "        If required_only is True, optional arguments (with default values)\n",
    "        are not included into output.\n",
    "        \"\"\"\n",
    "        sig = get_signature(function)\n",
    "        function_args = list(six.iterkeys(sig.parameters))\n",
    "        for param_name, p in six.iteritems(sig.parameters):\n",
    "        if (p.kind in (Parameter.VAR_POSITIONAL, Parameter.VAR_KEYWORD) \n",
    "            or (required_only and p.default is not Parameter.empty)):\n",
    "            function_args.remove(param_name)\n",
    "        \n",
    "        return function_args \n",
    "    \n",
    "    def roll(self.binned_data):\n",
    "        for y in tqdm_notebook(binned_data.keys()):\n",
    "            model_ranges[y] = self.function(binned_data[y][:,1]) # [:,1] needed only if binned_data is np.array. \n",
    "                                                           # use .append() instead of = if model_ranges is dict \n",
    "                                                           # as opposed to defaultdict\n",
    "        print(f\"Running cases from: {y}\") \n",
    "        \n",
    "    return model_ranges    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
